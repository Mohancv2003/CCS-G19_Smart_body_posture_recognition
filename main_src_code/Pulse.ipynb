{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcf37b1-acc9-4797-b337-e788d7d72c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing live feed..\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Warning\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    dist = m.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist\n",
    "\n",
    "# Calculate angle.\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = m.acos((y2 -y1)*(-y1) / (m.sqrt((x2 - x1)**2 + (y2 - y1)**2) * y1))\n",
    "    degree = int(180/m.pi)*theta\n",
    "    return degree\n",
    "\n",
    "\n",
    "def sendWarning():\n",
    "    print(\"Warning\")\n",
    "    pass\n",
    "\n",
    "# Initilize frame counters.\n",
    "good_frames = 0\n",
    "bad_frames = 0\n",
    "\n",
    "# Font type.\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Colors.\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "\n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(False,2)\n",
    "\n",
    "# Initialize webcam capture for live video feed.\n",
    "cap = cv2.VideoCapture(0)  # Change this to 0 for webcam\n",
    "\n",
    "# Meta.\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Initialize video writer if you want to save the output.\n",
    "video_output = cv2.VideoWriter('output_live.mp4', fourcc, fps, frame_size)\n",
    "\n",
    "print('Processing live feed..')\n",
    "while cap.isOpened():\n",
    "    # Capture frames from webcam.\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Null.Frames\")\n",
    "        break\n",
    "\n",
    "    # Get fps.\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # Get height and width.\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Convert the BGR image to RGB.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image.\n",
    "    keypoints = pose.process(image)\n",
    "\n",
    "    # Convert the image back to BGR.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Use lm and lmPose as representative of the following methods.\n",
    "    lm = keypoints.pose_landmarks\n",
    "    lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "    # Acquire the landmark coordinates if available.\n",
    "    if lm:\n",
    "        # Left shoulder.\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        # Right shoulder.\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        # Left ear.\n",
    "        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n",
    "        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n",
    "        # Left hip.\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "        #Left Knee\n",
    "        l_knee_x=int(lm.landmark[lmPose.LEFT_KNEE].x*w)\n",
    "        l_knee_y=int(lm.landmark[lmPose.LEFT_KNEE].y*h)\n",
    "        #Left Ankle\n",
    "        l_ankle_x=int(lm.landmark[lmPose.LEFT_ANKLE].x*w)\n",
    "        l_ankle_y=int(lm.landmark[lmPose.LEFT_ANKLE].y*h)\n",
    "        # Left Elbow\n",
    "        l_elbow_x=int(lm.landmark[lmPose.LEFT_ELBOW].x*w)\n",
    "        l_elbow_y=int(lm.landmark[lmPose.LEFT_ELBOW].y*h)\n",
    "        # Left Wrist\n",
    "        l_wrist_x=int(lm.landmark[lmPose.LEFT_WRIST].x*w)\n",
    "        l_wrist_y=int(lm.landmark[lmPose.LEFT_WRIST].y*h)\n",
    "\n",
    "        # Calculate distance between left shoulder and right shoulder points.\n",
    "        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "\n",
    "        # Assist to align the camera to point at the side view of the person.\n",
    "        if offset < 100:\n",
    "            cv2.putText(image, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)\n",
    "        else:\n",
    "            cv2.putText(image, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)\n",
    "\n",
    "        # Calculate angles.\n",
    "        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "        knee_inclination = findAngle(l_knee_x, l_knee_y, l_hip_x, l_hip_y)\n",
    "        ankle_inclination = findAngle(l_ankle_x, l_ankle_y, l_knee_x, l_knee_y)\n",
    "        shldr_inclination = findAngle(l_shldr_x, l_shldr_y, l_elbow_x, l_elbow_y)\n",
    "        elbow_inclination = findAngle(l_elbow_x, l_elbow_y, l_wrist_x, l_wrist_y)\n",
    "\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ankle_x, l_ankle_y), 3, yellow, -1)\n",
    "        cv2.circle(image, (l_knee_x, l_knee_y), 3, yellow, -1)\n",
    "\n",
    "    # Let's take y - coordinate of P3 100px above x1,  for display elegance.\n",
    "    # Although we are taking y = 0 while calculating angle between P1,P2,P3.\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "\n",
    "    # Similarly, here we are taking y - coordinate 100px above x1. Note that\n",
    "    # you can take any value for y, not necessarily 100 or 200 pixels.\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_knee_x, l_knee_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ankle_x, l_ankle_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_elbow_x-100, l_elbow_y ), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_elbow_x, l_elbow_y ), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_wrist_x, l_wrist_y ), 7, yellow, -1)\n",
    "\n",
    "    # Put text, Posture and angle inclination.\n",
    "    # Text string for display.\n",
    "        angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination)) + 'Shldr : '+ str(int(shldr_inclination)) + 'Elbow : '+ str(int(elbow_inclination))\n",
    "\n",
    "    # Determine whether good posture or bad posture.\n",
    "    # The threshold angles have been set based on intuition.\n",
    "        if neck_inclination < 25 and torso_inclination < 8 and knee_inclination > 85 and knee_inclination < 95 and ankle_inclination < 6 and shldr_inclination< 150 and shldr_inclination>120 and elbow_inclination<95 and elbow_inclination>85:\n",
    "            bad_frames = 0\n",
    "            good_frames += 1\n",
    "\n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(knee_inclination)), (l_knee_x + 10, l_knee_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(ankle_inclination)), (l_ankle_x + 10, l_ankle_y), font, 0.9, light_green, 2)\n",
    "\n",
    "        # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "            cv2.line(image, (l_knee_x, l_knee_y), (l_hip_x, l_hip_y), green, 4)\n",
    "            cv2.line(image, (l_knee_x, l_knee_y), (l_ankle_x, l_ankle_y), green, 4)\n",
    "            cv2.line(image, (l_ankle_x, l_ankle_y), (l_ankle_x, l_ankle_y-100), green, 4)\n",
    "            cv2.line(image, (l_knee_x, l_knee_y), (l_knee_x, l_knee_y-100), green, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_elbow_x, l_elbow_y), green, 4)\n",
    "            cv2.line(image, (l_wrist_x, l_wrist_y), (l_elbow_x, l_elbow_y), green, 4)\n",
    "            cv2.line(image, (l_elbow_x, l_elbow_y), (l_elbow_x-100, l_elbow_y), green, 4)\n",
    "\n",
    "        else:\n",
    "            good_frames = 0\n",
    "            bad_frames += 1\n",
    "\n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(knee_inclination)), (l_knee_x + 10, l_knee_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(ankle_inclination)), (l_ankle_x + 10, l_ankle_y), font, 0.9, red, 2)\n",
    "\n",
    "        # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), red, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), red, 4)\n",
    "            cv2.line(image, (l_knee_x, l_knee_y), (l_hip_x, l_hip_y), red, 4)\n",
    "            cv2.line(image, (l_knee_x, l_knee_y), (l_ankle_x, l_ankle_y), red, 4)\n",
    "            cv2.line(image, (l_ankle_x, l_ankle_y), (l_ankle_x, l_ankle_y-100), red, 4)\n",
    "            cv2.line(image, (l_knee_x, l_knee_y), (l_knee_x, l_knee_y-100), red, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_elbow_x, l_elbow_y), red, 4)\n",
    "            cv2.line(image, (l_wrist_x, l_wrist_y), (l_elbow_x, l_elbow_y), red, 4)\n",
    "            cv2.line(image, (l_elbow_x, l_elbow_y), (l_elbow_x-100, l_elbow_y), red, 4)\n",
    "\n",
    "    # Calculate the time of remaining in a particular posture.\n",
    "        good_time = (1 / fps) * good_frames\n",
    "        bad_time =  (1 / fps) * bad_frames\n",
    "\n",
    "    # Pose time.\n",
    "        if good_time > 0:\n",
    "            time_string_good = 'Good Posture Time : ' + str(round(good_time, 1)) + 's'\n",
    "            cv2.putText(image, time_string_good, (10, h - 20), font, 0.9, green, 2)\n",
    "        else:\n",
    "            time_string_bad = 'Bad Posture Time : ' + str(round(bad_time, 1)) + 's'\n",
    "            cv2.putText(image, time_string_bad, (10, h - 20), font, 0.9, red, 2)\n",
    "\n",
    "    # If you stay in bad posture for more than 3 minutes (180s) send an alert.\n",
    "        if bad_time > 3:\n",
    "            sendWarning()\n",
    "\n",
    "        # Drawing landmarks and checking posture\n",
    "        # Same logic as before for good and bad frames...\n",
    "\n",
    "    # Show the frame.\n",
    "    cv2.imshow('Posture Analysis', image)\n",
    "\n",
    "    # Write frames to output file.\n",
    "    video_output.write(image)\n",
    "\n",
    "    # Break loop if 'q' is pressed.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print('Finished.')\n",
    "cap.release()\n",
    "video_output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f932c1-e461-4acc-9aab-f1ed7742d155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
