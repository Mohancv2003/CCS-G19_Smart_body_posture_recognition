{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248393ae-1397-4e8c-bdf5-4c9843aec481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2c79bd-1ca0-404d-bdac-dece9f4a12c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing live feed..\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Colors.\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "\n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialize webcam capture for live video feed.\n",
    "cap = cv2.VideoCapture(0)  # Change this to 0 for webcam\n",
    "\n",
    "# Meta.\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Initialize video writer if you want to save the output.\n",
    "video_output = cv2.VideoWriter('output_live.mp4', fourcc, fps, frame_size)\n",
    "\n",
    "print('Processing live feed..')\n",
    "while cap.isOpened():\n",
    "    # Capture frames from webcam.\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Null.Frames\")\n",
    "        break\n",
    "\n",
    "    # Get fps.\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # Get height and width.\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Convert the BGR image to RGB.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image.\n",
    "    keypoints = pose.process(image)\n",
    "\n",
    "    # Convert the image back to BGR.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Use lm and lmPose as representative of the following methods.\n",
    "    lm = keypoints.pose_landmarks\n",
    "    lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "    # Acquire the landmark coordinates if available.\n",
    "    if lm:\n",
    "        #Nose-0\n",
    "        nose_x=int(lm.landmark[lmPose.NOSE].x*w)\n",
    "        nose_y=int(lm.landmark[lmPose.NOSE].y*h)\n",
    "        \n",
    "        #Left Eye Inner-1\n",
    "        l_eye_inner_x=int(lm.landmark[lmPose.LEFT_EYE_INNER].x*w)\n",
    "        l_eye_inner_y=int(lm.landmark[lmPose.LEFT_EYE_INNER].y*h)\n",
    "        \n",
    "        #Left Eye-2\n",
    "        l_eye_x=int(lm.landmark[lmPose.LEFT_EYE].x*w)\n",
    "        l_eye_y=int(lm.landmark[lmPose.LEFT_EYE].y*h)\n",
    "        \n",
    "        #Left Eye Outer-3\n",
    "        l_eye_outer_x=int(lm.landmark[lmPose.LEFT_EYE_OUTER].x*w)\n",
    "        l_eye_outer_y=int(lm.landmark[lmPose.LEFT_EYE_OUTER].y*h)\n",
    "        \n",
    "        #Right Eye Inner-4\n",
    "        r_eye_inner_x=int(lm.landmark[lmPose.RIGHT_EYE_INNER].x*w)\n",
    "        r_eye_inner_y=int(lm.landmark[lmPose.RIGHT_EYE_INNER].y*h)\n",
    "        \n",
    "        #Right Eye-5\n",
    "        r_eye_x=int(lm.landmark[lmPose.RIGHT_EYE].x*w)\n",
    "        r_eye_y=int(lm.landmark[lmPose.RIGHT_EYE].y*h)\n",
    "        \n",
    "        #Right Eye Outer-6\n",
    "        r_eye_outer_x=int(lm.landmark[lmPose.RIGHT_EYE_OUTER].x*w)\n",
    "        r_eye_outer_y=int(lm.landmark[lmPose.RIGHT_EYE_OUTER].y*h)\n",
    "        \n",
    "        #Left ear-7\n",
    "        l_ear_x=int(lm.landmark[lmPose.LEFT_EAR].x*w)\n",
    "        l_ear_y=int(lm.landmark[lmPose.LEFT_EAR].y*h)\n",
    "        \t\n",
    "        #Right ear-8\n",
    "        r_ear_x=int(lm.landmark[lmPose.RIGHT_EAR].x*w)\n",
    "        r_ear_y=int(lm.landmark[lmPose.RIGHT_EAR].y*h)\n",
    "        \n",
    "        #Left Mouth-9\n",
    "        l_mouth_x=int(lm.landmark[lmPose.MOUTH_LEFT].x*w)\n",
    "        l_mouth_y=int(lm.landmark[lmPose.MOUTH_LEFT].y*h)\n",
    "        \n",
    "        #Left Mouth-10\n",
    "        r_mouth_x=int(lm.landmark[lmPose.MOUTH_RIGHT].x*w)\n",
    "        r_mouth_y=int(lm.landmark[lmPose.MOUTH_RIGHT].y*h)\n",
    "        \n",
    "        # Left shoulder-11\n",
    "        l_shldr_x=int(lm.landmark[lmPose.LEFT_SHOULDER].x*w)\n",
    "        l_shldr_y=int(lm.landmark[lmPose.LEFT_SHOULDER].y*h)\n",
    "        \n",
    "        #Right shoulder-12\n",
    "        r_shldr_x=int(lm.landmark[lmPose.RIGHT_SHOULDER].x*w)\n",
    "        r_shldr_y=int(lm.landmark[lmPose.RIGHT_SHOULDER].y*h)\n",
    "        \n",
    "        # Left Elbow-13\n",
    "        l_elbow_x=int(lm.landmark[lmPose.LEFT_ELBOW].x*w)\n",
    "        l_elbow_y=int(lm.landmark[lmPose.LEFT_ELBOW].y*h)\n",
    "        \n",
    "        #Right Elbowr-14\n",
    "        r_elbow_x=int(lm.landmark[lmPose.RIGHT_ELBOW].x*w)\n",
    "        r_elbow_y=int(lm.landmark[lmPose.RIGHT_ELBOW].y*h)\n",
    "        \n",
    "        # Left Wrist-15\n",
    "        l_wrist_x=int(lm.landmark[lmPose.LEFT_WRIST].x*w)\n",
    "        l_wrist_y=int(lm.landmark[lmPose.LEFT_WRIST].y*h)\n",
    "        \n",
    "        #Right Wrist-16\n",
    "        r_wrist_x=int(lm.landmark[lmPose.RIGHT_WRIST].x*w)\n",
    "        r_wrist_y=int(lm.landmark[lmPose.RIGHT_WRIST].y*h)\n",
    "        \n",
    "        # Left Pinky-17\n",
    "        l_pinky_x=int(lm.landmark[lmPose.LEFT_PINKY].x*w)\n",
    "        l_pinky_y=int(lm.landmark[lmPose.LEFT_PINKY].y*h)\n",
    "        \n",
    "        #Right Pinky-18\n",
    "        r_pinky_x=int(lm.landmark[lmPose.RIGHT_PINKY].x*w)\n",
    "        r_pinky_y=int(lm.landmark[lmPose.RIGHT_PINKY].y*h)\n",
    "        \n",
    "        # Left Index-19\n",
    "        l_index_x=int(lm.landmark[lmPose.LEFT_INDEX].x*w)\n",
    "        l_index_y=int(lm.landmark[lmPose.LEFT_INDEX].y*h)\n",
    "        \n",
    "        #Right Index-20\n",
    "        r_index_x=int(lm.landmark[lmPose.RIGHT_INDEX].x*w)\n",
    "        r_index_y=int(lm.landmark[lmPose.RIGHT_INDEX].y*h)\n",
    "        \n",
    "        # Left Thumb-21\n",
    "        l_thumb_x=int(lm.landmark[lmPose.LEFT_THUMB].x*w)\n",
    "        l_thumb_y=int(lm.landmark[lmPose.LEFT_THUMB].y*h)\n",
    "        \n",
    "        #Right Thumb-22\n",
    "        r_thumb_x=int(lm.landmark[lmPose.RIGHT_THUMB].x*w)\n",
    "        r_thumb_y=int(lm.landmark[lmPose.RIGHT_THUMB].y*h)\n",
    "        \n",
    "        #Left hip-23\n",
    "        l_hip_x=int(lm.landmark[lmPose.LEFT_HIP].x*w)\n",
    "        l_hip_y=int(lm.landmark[lmPose.LEFT_HIP].y*h)\n",
    "        \n",
    "        #Right hip-24\n",
    "        r_hip_x=int(lm.landmark[lmPose.RIGHT_HIP].x*w)\n",
    "        r_hip_y=int(lm.landmark[lmPose.RIGHT_HIP].y*h)\n",
    "        \n",
    "        #Left Knee-25\n",
    "        l_knee_x=int(lm.landmark[lmPose.LEFT_KNEE].x*w)\n",
    "        l_knee_y=int(lm.landmark[lmPose.LEFT_KNEE].y*h)\n",
    "        \n",
    "        #Right Knee-26\n",
    "        r_knee_x=int(lm.landmark[lmPose.RIGHT_KNEE].x*w)\n",
    "        r_knee_y=int(lm.landmark[lmPose.RIGHT_KNEE].y*h)\n",
    "        \n",
    "        #Left Ankle-27\n",
    "        l_ankle_x=int(lm.landmark[lmPose.LEFT_ANKLE].x*w)\n",
    "        l_ankle_y=int(lm.landmark[lmPose.LEFT_ANKLE].y*h)\n",
    "        \n",
    "        #Right Ankle-28\n",
    "        r_ankle_x=int(lm.landmark[lmPose.RIGHT_ANKLE].x*w)\n",
    "        r_ankle_y=int(lm.landmark[lmPose.RIGHT_ANKLE].y*h)\n",
    "        \n",
    "        #Left Heel-29\n",
    "        l_heel_x=int(lm.landmark[lmPose.LEFT_HEEL].x*w)\n",
    "        l_heel_y=int(lm.landmark[lmPose.LEFT_HEEL].y*h)\n",
    "        \n",
    "        #Right Heel-30\n",
    "        r_heel_x=int(lm.landmark[lmPose.RIGHT_HEEL].x*w)\n",
    "        r_heel_y=int(lm.landmark[lmPose.RIGHT_HEEL].y*h)\n",
    "        \n",
    "        #Left Foot Index-31\n",
    "        l_foot_index_x=int(lm.landmark[lmPose.LEFT_FOOT_INDEX].x*w)\n",
    "        l_foot_index_y=int(lm.landmark[lmPose.LEFT_FOOT_INDEX].y*h)\n",
    "        \n",
    "        #Right Foot Index-32\n",
    "        r_foot_index_x=int(lm.landmark[lmPose.RIGHT_FOOT_INDEX].x*w)\n",
    "        r_foot_index_y=int(lm.landmark[lmPose.RIGHT_FOOT_INDEX].y*h)\n",
    "\n",
    "        cv2.circle(image, (nose_x, nose_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_eye_inner_x, l_eye_inner_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_eye_x, l_eye_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_eye_outer_x, l_eye_outer_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_eye_inner_x, r_eye_inner_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_eye_x, r_eye_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_eye_outer_x, r_eye_outer_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_ear_x, r_ear_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_mouth_x, l_mouth_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_mouth_x, r_mouth_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_elbow_x, l_elbow_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_elbow_x, r_elbow_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_wrist_x, l_wrist_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_wrist_x, r_wrist_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_pinky_x, l_pinky_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_pinky_x, r_pinky_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_index_x, l_index_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_index_x, r_index_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_thumb_x, l_thumb_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_thumb_x, r_thumb_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_hip_x, r_hip_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_knee_x, l_knee_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_knee_x, r_knee_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ankle_x, l_ankle_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_ankle_x, r_ankle_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_heel_x, l_heel_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_heel_x, r_heel_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_foot_index_x, l_foot_index_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_foot_index_x, r_foot_index_y), 7, yellow, -1)\n",
    "        \n",
    "    cv2.imshow('Posture Analysis', image)\n",
    "\n",
    "    # Write frames to output file.\n",
    "    video_output.write(image)\n",
    "\n",
    "    # Break loop if 'q' is pressed.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print('Finished.')\n",
    "cap.release()\n",
    "video_output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ea354-aab7-401a-a822-dd9942a9a1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
